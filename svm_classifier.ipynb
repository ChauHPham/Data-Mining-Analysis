{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b51554",
   "metadata": {},
   "source": [
    "# **Support Vector Machine (SVM) Classifier - CMPT 459 Course Project**\n",
    "\n",
    "This notebook demonstrates the process of training a **SVM Classifier** and evaluating it on a test/train split of the diabetic patient dataset. At the end, the evaluation metrics are printed and visualized.\n",
    "\n",
    "We do the following:\n",
    "- Data preprocessing consistent with the project pipeline\n",
    "- PCA for dimensionality reduction for visualization of results\n",
    "- 2D Visualization of the separating hyperplane superimposed on the data\n",
    "- Custom implemention of **soft SVM classifer without kernel** ( `svm_classifier.py`)\n",
    "- Accuracy score and precision/recall/fscore evaluation metrics to rate the correctness of the SVM classifier \n",
    "\n",
    "This notebook is part of our group’s modular report and references:\n",
    "- `svm_classifier.py`(original script version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6863a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "from svm_classifier import SVMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad7789",
   "metadata": {},
   "source": [
    "##  Loading and Preprocessing Data \n",
    "\n",
    "Following the same loading and preprocessing data process as the rest of the project, we apply the following:\n",
    "\n",
    "- Replace `'?'` values with `NaN`  \n",
    "- Drop columns with >40% missing values \n",
    "- One-hot encode high-cardinality categorical columns  \n",
    "- Label-encode low-cardinality categorical features  \n",
    "- Normalize numerical features  \n",
    "- Encode our target variable `readmitted` as integers:  \n",
    "  - `NO → 0`, `>30 → 1`, `<30 → 2`  \n",
    "- Remove sensitive/identifying data: `encounter_id`, `patient_nbr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0646342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(path: str):\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "    df = df.replace('?', np.nan)\n",
    "\n",
    "    # Drop columns with >40% missing\n",
    "    threshold = 0.4 * len(df)\n",
    "    df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "    # Fill categorical NAs\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    # Encode target\n",
    "    df[\"readmitted\"] = df[\"readmitted\"].map({'NO': 0, '>30': 1, '<30': 2})\n",
    "\n",
    "    # Encode categorical\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    le = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        if df[col].nunique() < 10:\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "        else:\n",
    "            df = pd.get_dummies(df, columns=[col], drop_first=True)\n",
    "\n",
    "    # Drop IDs\n",
    "    for col in [\"encounter_id\", \"patient_nbr\"]:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "\n",
    "    # Scale numeric\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "    X = df.drop(columns=[\"readmitted\"]).values\n",
    "    y = df[\"readmitted\"].values\n",
    "    print(\"Preprocessing complete! Final shape:\", X.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b03b7",
   "metadata": {},
   "source": [
    "## PCA Dimensionality Reduction \n",
    "\n",
    "We reduce dimensionality to **50 principal components**, preserving ~85–90% variance.  We use PCA to reduce dimensionality of the dataset to **50 principal components**, preserving ~85-90% variance. Doing so allows us to speed up the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccd913",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 50\n",
    "random_state = 42 \n",
    "pca = PCA(n_components, random_state)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(\"PCA shape:\", X_pca.shape)\n",
    "print(\"PCA done running. Explained variance:\", np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b94c6",
   "metadata": {},
   "source": [
    "##  Training SVM Classifier\n",
    "\n",
    "Before we begin to train the SVM classifier, we split the preprocessed data into test/train sets with a default test to train set ratio of 0.2. \n",
    "\n",
    "The accuracy of the separating hyperplane heavily depends on the choice of learning rate (alpha), margin tradeoff (lambda) and the number of iterations we allow the classifer to run for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844beee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_and_preprocess_data(\"data/diabetic_data.csv\")\n",
    "test_size = 0.2 \n",
    "random_state = 42\n",
    "alpha = 0.001\n",
    "lmda = 0.01\n",
    "iterations = 100\n",
    "# Create train/test split of data \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = test_size, random_state, stratify = y\n",
    ")\n",
    "\n",
    "# Train Soft SVM\n",
    "svm = SVMClassifier(\n",
    "    alpha = alpha,\n",
    "    lmda = lmda,\n",
    "    num_iterations = iterations\n",
    ")\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c868a",
   "metadata": {},
   "source": [
    "## 2D Visualization of Separating Hyperplane\n",
    "\n",
    "With function `getHyperplane`, we draw the equation of the hyperplane with input: weights, intercept and offset.\n",
    "\n",
    "For visualization, we plot the 50-dim PCA data into a 2D plot. Then, we superimpose the generated hyperplane onto the graph, separating the class labels. \n",
    "\n",
    "*Dotted line = hyperplane*\n",
    "*Solid line = margin*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHyperplane(X: np.ndarray, weights, b, offset):\n",
    "    \"\"\" Helper function for visualization of hyperplanes.\"\"\"\n",
    "    # Hyperplane equation: X_i * W + b = 0\n",
    "    # Draws a plane with soft margins  \n",
    "    hyperplane = (-weights[0] * X + b + offset) / weights[1]\n",
    "    return hyperplane\n",
    "\n",
    "print(\"Reducing data via PCA for 2D Visualization\")\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Plot for linear SVM Classification\", fontsize = 14, fontweight = \"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dddc0a",
   "metadata": {},
   "source": [
    "## Classification Evaluation Metrics\n",
    "\n",
    "We use the following metrics to evaluate the predictions made by the SVM Classifer:\n",
    "- **Accuracy**: computes the number of correctly classified labels\n",
    "- **Precision**: computes the ratio of true positive to all true positive and false positive (classified as positive) labels \n",
    "- **Recall**: computes the ratio of true positive to all true positive and false negative (classified as negative) labels \n",
    "- **F-score**: computes the weighted harmonic mean of precision and recall metrics, between (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, label_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_test, label_pred, average = 'weighted', zero_division = 0\n",
    ")\n",
    "\n",
    "print(\"\\nClassification Results:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559eb17",
   "metadata": {},
   "source": [
    "# **Interpretation & Discussion**\n",
    "## **Strengths of Soft SVM Classification**\n",
    "\n",
    "* Soft constraints on margin and slack variables speeds up runtime quite significantly (considering that the SVM Classifier runs in quadratic time) and allows for non-linear surfaces.\n",
    "* Effective in high-dimensional spaces where dimensions may surpass the number of samples.\n",
    "* Memory efficient as SVM utilizes a subset of training points (support vectors).\n",
    "\n",
    "---\n",
    "\n",
    "## **Problems of Soft SVM Classification**\n",
    "\n",
    "* Due to the nature of creating a separating hyperplane, the SVM classifier can only handle 2-class (binary) target classification and does not work for multi-class labels.\n",
    "* Running time at worse case (highly dependent on kernel choice, data size, misclassification penalty C)goes from **O(n^2)** to **O(n^3)** for small to large choice of C. It has at least quadratic running time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
