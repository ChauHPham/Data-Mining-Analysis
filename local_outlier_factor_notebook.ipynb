{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Local Outlier Factor (LOF) - Anomaly Detection**\n",
    "# **CMPT 459 Course Project**\n",
    "\n",
    "This notebook demonstrates **Local Outlier Factor** for outlier detection:\n",
    "* Preprocessing pipeline\n",
    "* LOF algorithm\n",
    "* **2D scatter plot visualization** using PCA\n",
    "* LOF score distribution\n",
    "* Interpretation of results\n",
    "\n",
    "**Reference**: `outlier_detection.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data Preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (101766, 50)\n",
      "Final shape: (101766, 2376)\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess(path):\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    df = df.replace(\"?\", np.nan)\n",
    "    threshold = 0.5 * len(df)\n",
    "    df = df.dropna(thresh=threshold, axis=1)\n",
    "    for col in [\"encounter_id\", \"patient_nbr\", \"readmitted\"]:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for col in cat_cols:\n",
    "        if df[col].nunique() > 10:\n",
    "            dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "            df = pd.concat([df.drop(columns=[col]), dummies], axis=1)\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].fillna(\"Unknown\"))\n",
    "    df = df.fillna(df.median())\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df)\n",
    "    print(f\"Final shape: {X.shape}\")\n",
    "    return X\n",
    "\n",
    "X = load_and_preprocess(\"data/diabetic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Local Outlier Factor Model**\n",
    "\n",
    "**How it works**:\n",
    "* Compares local density of each point to its neighbors\n",
    "* Points in sparse regions are flagged as outliers\n",
    "* LOF > 1 indicates outlier, LOF ≈ 1 indicates normal\n",
    "\n",
    "**Note**: LOF can be slow on large datasets, so we sample if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Sampling 10000 points for LOF (dataset has 101766 points)\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.01\n",
    "max_samples = 10000\n",
    "\n",
    "# Sample if dataset is large\n",
    "if len(X) > max_samples:\n",
    "    print(f\"⚠ Sampling {max_samples} points for LOF (dataset has {len(X)} points)\")\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(X), max_samples, replace=False)\n",
    "    X_sample = X[indices]\n",
    "else:\n",
    "    X_sample = X\n",
    "    indices = np.arange(len(X))\n",
    "\n",
    "print(f\"\\nFitting LOF (n_neighbors={n_neighbors}, contamination={contamination})...\")\n",
    "lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, n_jobs=-1)\n",
    "predictions = lof.fit_predict(X_sample)\n",
    "scores = lof.negative_outlier_factor_\n",
    "\n",
    "outlier_indices = np.where(predictions == -1)[0]\n",
    "n_outliers = len(outlier_indices)\n",
    "\n",
    "print(f\"\\n✓ Detected {n_outliers} outliers ({n_outliers/len(X_sample)*100:.2f}%)\")\n",
    "print(f\"Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "print(f\"\\nInterpretation: More negative scores = stronger outlier signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualization with PCA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying PCA for visualization...\")\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_sample)\n",
    "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Outliers highlighted\n",
    "inlier_mask = predictions == 1\n",
    "outlier_mask = predictions == -1\n",
    "\n",
    "axes[0].scatter(X_pca[inlier_mask, 0], X_pca[inlier_mask, 1],\n",
    "               c=\"blue\", alpha=0.3, s=20, label=\"Inliers\")\n",
    "axes[0].scatter(X_pca[outlier_mask, 0], X_pca[outlier_mask, 1],\n",
    "               c=\"red\", alpha=0.8, s=50, marker=\"x\", label=\"Outliers\")\n",
    "axes[0].set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%})\")\n",
    "axes[0].set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%})\")\n",
    "axes[0].set_title(\"LOF: Outliers vs Inliers\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Score distribution\n",
    "axes[1].hist(scores, bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "threshold = scores[outlier_mask].max() if outlier_mask.any() else scores.min()\n",
    "axes[1].axvline(threshold, color=\"red\", linestyle=\"--\", linewidth=2,\n",
    "               label=\"Outlier threshold\")\n",
    "axes[1].set_xlabel(\"Negative Outlier Factor\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].set_title(\"LOF Score Distribution\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interpretation & Discussion**\n",
    "\n",
    "### **How LOF Works**\n",
    "\n",
    "1. **Local Density**: Compute density around each point using k-nearest neighbors\n",
    "2. **Compare Densities**: Compare point's density to neighbors' densities\n",
    "3. **LOF Score**: \n",
    "   - LOF ≈ 1: Similar density to neighbors (normal)\n",
    "   - LOF > 1: Lower density than neighbors (outlier)\n",
    "\n",
    "### **Key Findings**\n",
    "\n",
    "* **Local vs Global**: LOF detects local anomalies, not just global outliers\n",
    "* **Score Interpretation**:\n",
    "  - Negative outlier factor shown (more negative = stronger outlier)\n",
    "  - Points in sparse regions have more negative scores\n",
    "\n",
    "### **Comparison: LOF vs Isolation Forest vs Elliptic Envelope**\n",
    "\n",
    "| Aspect | LOF | Isolation Forest | Elliptic Envelope |\n",
    "|--------|-----|------------------|-------------------|\n",
    "| **Method** | Density-based | Tree-based | Gaussian/Covariance-based |\n",
    "| **Speed** | Slower (O(n²)) | Faster (O(n log n)) | Fast (O(n) prediction) |\n",
    "| **Outlier Type** | Local anomalies | Global anomalies | Global anomalies |\n",
    "| **High Dimensions** | Suffers from curse | Handles well | Needs PCA/reduction |\n",
    "| **Interpretability** | More intuitive | Less interpretable | Very interpretable |\n",
    "| **Assumption** | Local density | None | Gaussian distribution |\n",
    "\n",
    "### **Strengths**\n",
    "* Detects local outliers in clustered data\n",
    "* Intuitive: based on neighborhood density\n",
    "* No assumptions about data distribution\n",
    "\n",
    "### **Limitations**\n",
    "* Slow on large datasets (O(n²) complexity)\n",
    "* Sensitive to k (number of neighbors)\n",
    "* Curse of dimensionality affects distance computation\n",
    "* Requires setting contamination parameter\n",
    "\n",
    "### **Medical Context**\n",
    "\n",
    "LOF-detected outliers may represent:\n",
    "1. **Unusual patient profiles**: Rare combinations of features\n",
    "2. **Data quality issues**: Measurement or recording errors\n",
    "3. **Special populations**: Subgroups requiring different treatment\n",
    "\n",
    "**Recommendation**: \n",
    "* Use **LOF** when you expect clustered anomalies or local density-based outliers\n",
    "* Use **Isolation Forest** for faster computation on large, high-dimensional datasets\n",
    "* Use **Elliptic Envelope** when data is roughly Gaussian and you want interpretable global outliers\n",
    "* Review common outliers detected by multiple methods (highest confidence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
